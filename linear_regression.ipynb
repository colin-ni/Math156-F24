{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will generate some noisy data from a plane, then write and train a linear regression model to learn the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method called `generate_data` that generates some data according to the following distributions:\n",
    "$$X_1 \\sim \\mathcal{N}(0, 10),$$\n",
    "$$X_2 \\sim \\mathcal{N}(0, 10),$$\n",
    "$$y = 3X_1 - 2X_2 + \\mathcal{N}(0, 5).$$\n",
    "It should take `n_samples` as a parameter and return two `np.ndarray`s, one of shape `(n_samples, 2)` and another of shape `(n_samples, )`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "n_samples = 1000\n",
    "X_train, y_train = generate_data(n_samples)\n",
    "assert X_train.shape == (n_samples, 2)\n",
    "assert y_train.shape == (n_samples, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training data in 3D using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple model to learn this data. Roughly speaking, it will take in this training data and try to figure out the equation of the plane, and as a result, given brand new `(x_1, x_2)` values, it will be able to predict their `y` values.\n",
    "\n",
    "To evaluate our model, we will use the mean-squared-error of our predictions. A \"normalized\" version of this is `R^2 = 1 - MSE / variance of y_true`, which is always between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "y_true = np.array([1, 5])\n",
    "y_pred = np.array([2, 4])\n",
    "assert MSE(y_true, y_pred) == 1\n",
    "assert R2(y_true, y_pred) == 1 - 1 / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us build our model. We can model a plane by $\\beta X$ for some vector $\\beta.$ To find $\\beta,$ we minimize\n",
    "$$\\text{MSE}(\\beta X, y) = (\\beta X - y)^T (\\beta X - y).$$\n",
    "Soon we will see that this amounts to setting the derivative equal to zero and solving for beta:\n",
    "$$\\beta = (X^TX)^{-1} X^T y.$$\n",
    "(For example, see https://en.wikipedia.org/wiki/Linear_regression#Least-squares_estimation_and_related_techniques.)\n",
    "\n",
    "Write a `LR` class that does this. It should have one attribute `beta` and two methods `fit` and `predict`. The `fit` method should take in training data `X` and `y` and determine `beta`, and the `predict` method should take in new data `X_test` and output its predictions. In particular, the `predict` method should assume that the model has already been fit to some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, generate some training data, train a LR model on it, generate some test data, and evaluate how well the model does on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: So far we have only considered data coming from planes that pass through the origin. There is a clean way to learn a bias term: add an extra `1` in front of your training data, i.e. change `(x_1, x_2)` to `(1, x_1, x_2)`, then increase the size of your `beta` vector by one. The `beta_0` term is then your bias term!\n",
    "\n",
    "Alter `generate_data` to take in an optional bias parameter: `generate_data(n_samples, bias=0)`. Then, alter your `LR` class to learn a bias term as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
